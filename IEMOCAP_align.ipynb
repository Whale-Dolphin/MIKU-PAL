{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def parse_utterance_block(block_lines):\n",
    "    \"\"\"解析单个话语块的数据\"\"\"\n",
    "    # 解析第一行\n",
    "    first_line = block_lines[0].strip().split('\\t')\n",
    "    time_str = first_line[0].strip('[]').split(' - ')\n",
    "\n",
    "    utterance = {\n",
    "        \"timing\": {\n",
    "            \"start\": float(time_str[0]),\n",
    "            \"end\": float(time_str[1])\n",
    "        },\n",
    "        \"id\": first_line[1],\n",
    "        \"final_emotion\": first_line[2],\n",
    "        \"dimensional_average\": {\n",
    "            \"valence\": float(first_line[3].strip('[]').split(', ')[0]),\n",
    "            \"activation\": float(first_line[3].strip('[]').split(', ')[1]),\n",
    "            \"dominance\": float(first_line[3].strip('[]').split(', ')[2])\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return utterance\n",
    "\n",
    "\n",
    "def create_json_structure(text, session_id):\n",
    "    \"\"\"创建完整的JSON结构\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    utterances = []\n",
    "    current_block = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip() == \"\" or line.startswith('%'):\n",
    "            if current_block:\n",
    "                utterances.append(parse_utterance_block(current_block))\n",
    "                current_block = []\n",
    "            continue\n",
    "        current_block.append(line)\n",
    "\n",
    "    if current_block:\n",
    "        utterances.append(parse_utterance_block(current_block))\n",
    "\n",
    "    return {\n",
    "        \"session_info\": {\n",
    "            \"session_id\": session_id,\n",
    "        },\n",
    "        \"utterances\": utterances\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for i in range(5):\n",
    "    path = f'/mnt/users/whaledolphin/FER-tts/MIKU-PAL-test/IEMOCAP_full_release/Session{i+1}/dialog/EmoEvaluation'\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    txt_files = [f for f in files if f.endswith('.txt')]\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        with open(os.path.join(path, txt_file), 'r') as f:\n",
    "            text = f.read()\n",
    "        json_data = create_json_structure(text, txt_file.split('.')[0])\n",
    "        with open(f'/mnt/users/whaledolphin/FER-tts/MIKU-PAL-test/IEMOCAP_full_release/IEMOCAP_session{i+1}.json', 'a') as json_file:\n",
    "            json.dump(json_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('models/dsfd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dsfd.inference import FaceDetect\n",
    "\n",
    "fd = FaceDetect(\n",
    "    confidence_threshold=0.5,\n",
    "    nms_iou_threshold=0.3,\n",
    "    max_resolution=640,\n",
    "    device='cuda:0',\n",
    "    fp16_inference=True,\n",
    "    clip_boxes=True,\n",
    "    model_path='checkpoints/dsfd.pth',\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muki-pal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
